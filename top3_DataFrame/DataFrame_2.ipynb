{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5e638a",
   "metadata": {},
   "source": [
    "<center><font size=6 color=\"#00416d\">DataFrame-2</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443177e",
   "metadata": {},
   "source": [
    "Here in this notebook we mainly learn how to filter a DataFrame for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "df = pd.read_csv(\"employees.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf77bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get big picture on data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f012fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save memory by performing some optimization\n",
    "# converting string type date into datetime object\n",
    "df[\"Start Date\"] = pd.to_datetime(df[\"Start Date\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ace8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the same way we convert Last Login Time\n",
    "# Since we are converting as a datetime it will take today as date\n",
    "df[\"Last Login Time\"] = pd.to_datetime(df[\"Last Login Time\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a192b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the similar way we perform of some of other columns too\n",
    "df[\"Gender\"] = df[\"Gender\"].astype(\"category\")\n",
    "df[\"Senior Management\"] = df[\"Senior Management\"].astype(\"category\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490d70c",
   "metadata": {},
   "source": [
    "Our memory usage decreased from 62.6 to 49.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above all things we can do in command\n",
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={'Gender':\"category\", \"Senior Management\":\"boolean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count number of null values in a column\n",
    "df[\"First Name\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460aaab",
   "metadata": {},
   "source": [
    "### Filter a DataFrame base on a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9de696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"],\n",
    "                 dtype={'Gender':\"category\", \"Senior Management\":\"boolean\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29dc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will return True if Team is Finance\n",
    "df[\"Team\"] == \"Finance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will fectch the rows who value is true\n",
    "df[df[\"Team\"] == \"Finance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c749392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have boolean data in your column you can directly use it\n",
    "df[df[\"Senior Management\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can fetch who value is greater than 100000\n",
    "df[df[\"Salary\"] >= 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also apply same logic on dates\n",
    "df[df[\"Start Date\"] >= \"2000-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef104de1",
   "metadata": {},
   "source": [
    "### To fetch all rows that does not match the condition (~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13021a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"],\n",
    "                 dtype={'Gender':\"category\", \"Senior Management\":\"boolean\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fetch all genders other than male\n",
    "df[~(df[\"Gender\"] == \"Male\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f0027",
   "metadata": {},
   "source": [
    "### Fetching multiple columns using AND - &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68940d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"],\n",
    "                 dtype={'Gender':\"category\", \"Senior Management\":\"boolean\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will fetch all the row whos Gender is Male and Team is Finance\n",
    "males = df[\"Gender\"] == \"Male\"\n",
    "finance = df[\"Team\"] == \"Finance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it will fetch the rows only if both values are true\n",
    "df[males & finance]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0532a0",
   "metadata": {},
   "source": [
    "###  Fetching multiple columns using or - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6505d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"],\n",
    "                dtype={'Gender':\"category\", \"Senior Management\":\"boolean\"})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56078f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fetch all rows who Gender is Male or who start date is after 2000-01-01\n",
    "male = df['Gender'] == \"Female\"\n",
    "start_date = df[\"Start Date\"] > \"2000-01-01\"\n",
    "df[male | start_date].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will combine both AND and OR\n",
    "# Condition-1: Gender should be Male and Start Date should be creater than 2015-01-01\n",
    "# Condition-2: If it does not satisfy condition then Team should be at lease Finance\n",
    "male = df['Gender'] == \"Female\"\n",
    "start_date = df[\"Start Date\"] > \"2015-01-01\"\n",
    "team = df[\"Team\"] == \"Finance\"\n",
    "df[(male & start_date) | team]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8df37",
   "metadata": {},
   "source": [
    "### .isin() method\n",
    "<b>Documentation:</b><a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html\">df.isin()</a><br>\n",
    "<b>Use:</b>To check whether each element in the DataFrame is contained in value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"America\": [4, 6, 8], \"India\": [1, 2, 3]}, index=[\"Car\", \"Bike\", \"Auto\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isin([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={\"Gender\":\"category\", \"Senior Management\":\"boolean\", \"Team\": \"category\"})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition-1: Let's bring all rows from DataFrame the maches \"Finance\", \"Marketing\", \"Client Service\" in \"Teams\" column\n",
    "condition = df[\"Team\"].isin([\"Finance\", \"Marketing\", \"Client Service\"])\n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da919e17",
   "metadata": {},
   "source": [
    "### The .isnull() and .notnull() methods\n",
    "<b>.isnull()</b>:<br>\n",
    "Documentation: <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html?highlight=isnull\">isnull</a> <br>\n",
    "Use:Detect missing values.<br><br>\n",
    "<b>.notnull()</b>: <br>\n",
    "Documentation:<a href=\"https://pandas.pydata.org/docs/reference/api/pandas.notnull.html\">notnull()</a><br>\n",
    "Use:Detect non-missing values for an array-like object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={\"Gender\":\"category\", \"Senior Management\":\"boolean\", \"Team\": \"category\"})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all NaN row based on Team column\n",
    "df[df[\"Team\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f23e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all Non NaN row based on Team column\n",
    "df[df[\"Team\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dbc0a",
   "metadata": {},
   "source": [
    "### The .between() method\n",
    "Documentation:<a href=\"https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html\">.between()</a><br>\n",
    "Use:Return boolean Series equivalent to left <= series <= right.<br>\n",
    "This function returns a boolean vector containing True wherever the corresponding Series element is between the boundary values left and right. NA values are treated as False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={\"Gender\":\"category\", \"Senior Management\":\"boolean\", \"Team\": \"category\"})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Salary\"].between(90000, 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Start Date\"].between(\"2001-09-21\", \"2002-09-21\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Last Login Time\"].between(\"10:00AM\", \"12:00PM\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e70d7a",
   "metadata": {},
   "source": [
    "### The .duplicated() method\n",
    "Return boolean Series denoting duplicate rows.<br>\n",
    "<b> Documentation</b>:<a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html?highlight=duplicate\">duplicated()</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'names':[\"Kiran\", \"Kiran\", \"James\", \"Kiran\", \"James\", \"Madhu\"],\n",
    "                   'ages':[20, 30, 45, 69, 59, 23]})\n",
    "df.sort_values(by=['names'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd70af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you keep last, let assume you have 3 duplicated element then first 2 will be true and 3rd element will be false\n",
    "df['names'].duplicated(keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If name repeats then it will set true\n",
    "condition = df['names'].duplicated(keep=False)\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fetch non dulicated rows\n",
    "df[~condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334d4e1",
   "metadata": {},
   "source": [
    "### The .drop_duplicates() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75867d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={\"Gender\":\"category\", \"Senior Management\":\"boolean\", \"Team\": \"category\"})\n",
    "df.sort_values(by=[\"First Name\"], inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c937693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce78a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is because there are no identical rows\n",
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows base on \"First Name\" column\n",
    "# By default it will drops the all rows except first occurence, \n",
    "# you can change it \"last\" if you want to keep \"last\" occurence by changing \"keep\" parameter value\n",
    "df.drop_duplicates(subset=[\"First Name\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop all duplicate rows if [\"First Name\"] is repeated by changing \"keep\" value to False\n",
    "df.drop_duplicates(subset=[\"First Name\"], keep=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Becareful while using drop_duplicates on category columns because most of the values are repeated\n",
    "df.drop_duplicates(subset=[\"Team\"], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbe114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61059444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also multiple columns to subset\n",
    "# which mean \"First Name\", \"Team\" are similar in more than 1 row then those all rows will get deleted\n",
    "df.drop_duplicates(subset=[\"First Name\", \"Team\"], keep=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4443501",
   "metadata": {},
   "source": [
    "### The .unique() and .nunique() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"employees.csv\", parse_dates=[\"Start Date\", \"Last Login Time\"], \n",
    "                 dtype={\"Gender\":\"category\", \"Senior Management\":\"boolean\", \"Team\": \"category\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Team\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65148f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It wouldn't count Null values\n",
    "df[\"Team\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count null values\n",
    "df[\"Team\"].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102cb0d2",
   "metadata": {},
   "source": [
    "## Synposis\n",
    "\n",
    "These are just provide one line description, go throgh the example to understand them in depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ec903",
   "metadata": {},
   "source": [
    "<table style=\"margin-left: 0;\">\n",
    "  <tr style=\"text-align:center;\">\n",
    "    <th>Implementation</th>\n",
    "    <th>Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[ condition1 & condition2 ]</td>\n",
    "      <td>It fetches the row if and only if the condition1 and condition2 are true</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[ condition1 | condition2 ]</td>\n",
    "      <td>It fetches the row if atleast one condition is true</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df.isin([value,...])<br> df[\"column\"].isin([value,...])</td>\n",
    "      <td>We can use is in method on both Series and DataFrame. It will return true if value is present</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].isnull()</td>\n",
    "      <td>Returns True if value is null else False</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].notnull()</td>\n",
    "      <td>Returns True if value is not null else False</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].between(start, end)</td>\n",
    "      <td>To fetch all rows that satisfies the range</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].duplicated()</td>\n",
    "      <td>Lets assume a name repeated thrice, then first two values marked as True and last value marked as False.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].drop_duplicates()</td>\n",
    "      <td>It drops all the duplicated rows</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].unique()</td>\n",
    "      <td>I will give the list of all unique values</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>df[\"column\"].nunique()</td>\n",
    "      <td>I will give the count of all unique values</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
